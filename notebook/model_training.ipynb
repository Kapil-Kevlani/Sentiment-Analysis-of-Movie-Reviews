{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import gc\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:/Users/kkmax/Desktop/end to end ML Deployment/Sentiment Analysis of movie reviews/notebook/data/IMDB Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.iloc[:5000,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kkmax\\AppData\\Local\\Temp\\ipykernel_13060\\2718399134.py:1: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['sentiment'] = df['sentiment'].replace({'positive':1, 'negative': 0})\n"
     ]
    }
   ],
   "source": [
    "df['sentiment'] = df['sentiment'].replace({'positive':1, 'negative': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['review']\n",
    "y = df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       One of the other reviewers has mentioned that ...\n",
       "1       A wonderful little production. <br /><br />The...\n",
       "2       I thought this was a wonderful way to spend ti...\n",
       "3       Basically there's a family where a little boy ...\n",
       "4       Petter Mattei's \"Love in the Time of Money\" is...\n",
       "                              ...                        \n",
       "4995    An interesting slasher film with multiple susp...\n",
       "4996    i watched this series when it first came out i...\n",
       "4997    Once again Jet Li brings his charismatic prese...\n",
       "4998    I rented this movie, after hearing Chris Gore ...\n",
       "4999    This was a big disappointment for me. I think ...\n",
       "Name: review, Length: 5000, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       1\n",
       "2       1\n",
       "3       0\n",
       "4       1\n",
       "       ..\n",
       "4995    0\n",
       "4996    1\n",
       "4997    1\n",
       "4998    0\n",
       "4999    0\n",
       "Name: sentiment, Length: 5000, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = HashingVectorizer()\n",
    "X_train = vectorizer.transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "def evaluate_model(true, predicted):\n",
    "    f1 = f1_score(true, predicted)\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier\n",
      "Model performance for Training set\n",
      "- F1 Score: 0.9992\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- F1 Score: 0.8116\n",
      "===================================\n",
      "\n",
      "\n",
      "RandomForestClassifier\n",
      "Model performance for Training set\n",
      "- F1 Score: 1.0000\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- F1 Score: 0.7913\n",
      "===================================\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kkmax\\Desktop\\end to end ML Deployment\\Sentiment Analysis of movie reviews\\venv\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier\n",
      "Model performance for Training set\n",
      "- F1 Score: 0.8280\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- F1 Score: 0.7844\n",
      "===================================\n",
      "\n",
      "\n",
      "Decision Tree\n",
      "Model performance for Training set\n",
      "- F1 Score: 1.0000\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- F1 Score: 0.6695\n",
      "===================================\n",
      "\n",
      "\n",
      "SVC\n",
      "Model performance for Training set\n",
      "- F1 Score: 0.9418\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- F1 Score: 0.8361\n",
      "===================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"XGBClassifier\": XGBClassifier(),\n",
    "    \"RandomForestClassifier\": RandomForestClassifier(),\n",
    "    \"AdaBoostClassifier\": AdaBoostClassifier(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"SVC\": SVC()\n",
    "}\n",
    "model_list = []\n",
    "f1_score_list =[]\n",
    "\n",
    "for i in range(len(list(models))):\n",
    "    model = list(models.values())[i]\n",
    "    model.fit(X_train, y_train) # Train model\n",
    "\n",
    "    # Make predictions\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    # Evaluate Train and Test dataset\n",
    "    model_train_f1_score = evaluate_model(y_train, y_train_pred)\n",
    "\n",
    "    model_test_f1_score = evaluate_model(y_test, y_test_pred)\n",
    "\n",
    "    \n",
    "    print(list(models.keys())[i])\n",
    "    model_list.append(list(models.keys())[i])\n",
    "    \n",
    "    print('Model performance for Training set')\n",
    "    print(\"- F1 Score: {:.4f}\".format(model_train_f1_score))\n",
    "\n",
    "    print('----------------------------------')\n",
    "    \n",
    "    print('Model performance for Test set')\n",
    "    print(\"- F1 Score: {:.4f}\".format(model_test_f1_score))\n",
    "    f1_score_list.append(model_test_f1_score)\n",
    "    print('='*35)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.836134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.811594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.791322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.784437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.669537</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model Name  F1 Score\n",
       "4                     SVC  0.836134\n",
       "0           XGBClassifier  0.811594\n",
       "1  RandomForestClassifier  0.791322\n",
       "2      AdaBoostClassifier  0.784437\n",
       "3           Decision Tree  0.669537"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(list(zip(model_list, f1_score_list)), columns=['Model Name', 'F1 Score']).sort_values(by=[\"F1 Score\"],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 1048576)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.10037712, -0.05018856, -0.05018856,  0.05018856, -0.05018856,\n",
       "       -0.05018856,  0.05018856,  0.05018856, -0.10037712,  0.05018856,\n",
       "       -0.05018856, -0.05018856,  0.10037712,  0.05018856,  0.05018856,\n",
       "        0.05018856,  0.10037712,  0.05018856,  0.05018856, -0.05018856,\n",
       "        0.10037712, -0.10037712, -0.25094281, -0.05018856, -0.10037712,\n",
       "       -0.05018856, -0.05018856,  0.05018856, -0.6524513 ,  0.05018856,\n",
       "       -0.05018856,  0.15056568, -0.05018856, -0.05018856, -0.05018856,\n",
       "       -0.05018856,  0.05018856,  0.05018856,  0.05018856,  0.05018856,\n",
       "       -0.05018856, -0.05018856,  0.05018856, -0.05018856,  0.05018856,\n",
       "        0.05018856,  0.15056568,  0.05018856, -0.10037712, -0.05018856,\n",
       "       -0.05018856, -0.05018856, -0.10037712,  0.10037712,  0.05018856,\n",
       "        0.05018856, -0.10037712,  0.05018856,  0.05018856,  0.20075425,\n",
       "        0.05018856, -0.05018856,  0.10037712,  0.05018856, -0.05018856,\n",
       "        0.05018856, -0.05018856, -0.05018856, -0.05018856, -0.05018856,\n",
       "       -0.05018856, -0.05018856, -0.05018856,  0.05018856, -0.05018856,\n",
       "        0.05018856,  0.25094281,  0.05018856, -0.10037712, -0.05018856,\n",
       "        0.05018856, -0.05018856,  0.05018856,  0.05018856,  0.05018856,\n",
       "       -0.05018856, -0.05018856, -0.10037712,  0.05018856, -0.05018856,\n",
       "       -0.15056568,  0.05018856, -0.05018856, -0.05018856, -0.05018856,\n",
       "       -0.05018856,  0.05018856, -0.05018856, -0.05018856, -0.05018856])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1048576)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = HashingVectorizer()\n",
    "a = 'my name is kapil', 'his name is raja'\n",
    "b = vectorizer.transform(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2,)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = c.reshape((2,1))\n",
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions except for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 1 and the array at index 1 has size 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[57], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m concatenated_array \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumn_stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43mc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(concatenated_array)\n",
      "File \u001b[1;32mc:\\Users\\kkmax\\Desktop\\end to end ML Deployment\\Sentiment Analysis of movie reviews\\venv\\lib\\site-packages\\numpy\\lib\\shape_base.py:652\u001b[0m, in \u001b[0;36mcolumn_stack\u001b[1;34m(tup)\u001b[0m\n\u001b[0;32m    650\u001b[0m         arr \u001b[38;5;241m=\u001b[39m array(arr, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, subok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, ndmin\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mT\n\u001b[0;32m    651\u001b[0m     arrays\u001b[38;5;241m.\u001b[39mappend(arr)\n\u001b[1;32m--> 652\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_nx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 1 and the array at index 1 has size 2"
     ]
    }
   ],
   "source": [
    "concatenated_array = np.column_stack((b,c))\n",
    "print(concatenated_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 1]\n",
      " [1 0 1 2]\n",
      " [0 1 0 3]]\n"
     ]
    }
   ],
   "source": [
    "sparse_matrix = np.array([[0, 1, 0], [1, 0, 1], [0, 1, 0]])\n",
    "categorical_feature = np.array([1, 2, 3])\n",
    "categorical_feature = categorical_feature.reshape((3, 1))\n",
    "concatenated_array = np.concatenate((sparse_matrix, categorical_feature), axis=1)\n",
    "print(concatenated_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the HashingVectorizer\n",
    "vectorizer1 = HashingVectorizer()\n",
    "\n",
    "# Example text data\n",
    "a = ['my name is kapil', 'his name is raja']\n",
    "\n",
    "# Transform text data into a sparse matrix\n",
    "b = vectorizer1.transform(a)\n",
    "\n",
    "# Example numerical data\n",
    "C = [1, 2]\n",
    "\n",
    "# Convert list C into a sparse matrix (with the same number of rows as b)\n",
    "C_sparse = csr_matrix(np.array(C).reshape(-1, 1))\n",
    "\n",
    "# Concatenate b and C_sparse horizontally\n",
    "result = hstack([b, C_sparse])\n",
    "\n",
    "# result is the final sparse matrix with b and C concatenated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.5,  0.5, -0.5,  0.5,  1. , -0.5,  0.5, -0.5,  0.5,  2. ])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx = result[:,:-1]\n",
    "yy = result[:,-1]\n",
    "#xx[0].data\n",
    "yy.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "yy_dense = yy.toarray().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yy_dense[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
